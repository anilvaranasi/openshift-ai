{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6752f7-6c4c-45df-bee9-7de7ecd2dfb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m202.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/app-root/lib/python3.9/site-packages (from opencv-python) (1.24.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545cf17",
   "metadata": {},
   "source": [
    "## Image-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f47ff271-449f-4b1e-90e1-1b7f2d2c64c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Function load image from disk\n",
    "def load_image(image_path):\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "# Function to preprocess image as per model requirements\n",
    "# More details at: https://github.com/onnx/models/tree/main/validated/vision/classification/resnet\n",
    "def preprocess_image(img):\n",
    "    # Resize image to minimum size of 256x256 while maintaining aspect ratio\n",
    "    min_size = min(img.shape[:2])\n",
    "    scale_factor = 256 / min_size\n",
    "    new_size = (int(img.shape[1] * scale_factor), int(img.shape[0] * scale_factor))\n",
    "    img_resized = cv2.resize(img, new_size)\n",
    "\n",
    "    # Crop 224x224 from the center\n",
    "    center_x = new_size[0] // 2\n",
    "    center_y = new_size[1] // 2\n",
    "    half_crop = 112\n",
    "    img_cropped = img_resized[center_y - half_crop:center_y + half_crop, center_x - half_crop:center_x + half_crop]\n",
    "\n",
    "    # Normalize pixel values\n",
    "    mean = np.array([0.485, 0.456, 0.406]) * 255\n",
    "    std = np.array([0.229, 0.224, 0.225]) * 255\n",
    "    img_normalized = (img_cropped - mean) / std\n",
    "\n",
    "    # Transpose image from HWC to CHW layout\n",
    "    img_transposed = np.transpose(img_normalized, (2, 0, 1))\n",
    "\n",
    "    return img_transposed\n",
    "\n",
    "# Function to convert image data to flat array\n",
    "def image_to_flat_array(image_data):\n",
    "    return image_data.flatten().tolist()\n",
    "\n",
    "# Function to convert image data to JSON format\n",
    "def image_to_json(image_data):\n",
    "    return json.dumps({\"inputs\": [{\"name\": \"data\", \"shape\": [1, 3, 224, 224], \"datatype\": \"FP32\", \"data\": image_data}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45282f",
   "metadata": {},
   "source": [
    "## Testing locally yields results for the deployed model on OpenShift AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2007431a-db74-4479-b295-00f296c922ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top prediction: n02206856 bee\n"
     ]
    }
   ],
   "source": [
    "# Path to the image file\n",
    "image_path = 'bee.jpg'\n",
    "\n",
    "# Load image\n",
    "image = load_image(image_path)\n",
    "\n",
    "# Preprocess image\n",
    "image_processed = preprocess_image(image)\n",
    "\n",
    "# Convert image to flat array and JSON format\n",
    "image_flat = image_to_flat_array(image_processed)\n",
    "image_json = image_to_json(image_flat)\n",
    "\n",
    "# Send request to OpenVINO server\n",
    "url = 'https://testing-mlops.apps.cluster-5djnl.dynamic.redhatworkshops.io/v2/models/testing/infer'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "try:\n",
    "    response = requests.post(url, data=image_json, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        # Parse response\n",
    "        results = json.loads(response.text)\n",
    "\n",
    "        # Get the top-5 class labels\n",
    "        with open('imagenet_classes.txt', 'r') as f:\n",
    "            class_labels = f.read().splitlines()\n",
    "\n",
    "        # Get the top-1 prediction\n",
    "        predictions = np.array(response.json()['outputs'][0]['data'])\n",
    "        top_prediction_idx = np.argmax(predictions)\n",
    "        top_prediction_label = class_labels[top_prediction_idx]\n",
    "\n",
    "        print(\"Top prediction:\", top_prediction_label)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27063304",
   "metadata": {},
   "source": [
    "## Hosting a Flask application on port 5000.\n",
    "## Sending a POST request for prediction from the proxy server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77d04a57-c4b2-4639-a4c8-9a442ba20d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /opt/app-root/lib/python3.9/site-packages (3.0.3)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/app-root/lib/python3.9/site-packages (from flask) (1.7.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/app-root/lib/python3.9/site-packages (from flask) (3.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /opt/app-root/lib/python3.9/site-packages (from flask) (7.0.1)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/app-root/lib/python3.9/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/app-root/lib/python3.9/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/app-root/lib/python3.9/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/app-root/lib/python3.9/site-packages (from importlib-metadata>=3.6.0->flask) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.132.2.11:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [26/Apr/2024 16:08:23] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2024 16:08:27] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2024 16:08:32] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2024 16:08:39] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2024 16:09:35] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2024 16:24:47] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "! pip install flask\n",
    "from flask import Flask, request, render_template\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Function to preprocess image (replace this with your actual preprocessing function)\n",
    "def preprocess_image(image):\n",
    "    # Your preprocessing code here\n",
    "    return image_processed\n",
    "\n",
    "# Function to load class labels\n",
    "def load_class_labels():\n",
    "    with open('imagenet_classes.txt', 'r') as f:\n",
    "        class_labels = f.read().splitlines()\n",
    "    return class_labels\n",
    "\n",
    "# Function to perform inference\n",
    "def perform_inference(image):\n",
    "    # Preprocess image\n",
    "    image_processed = preprocess_image(image)\n",
    "    \n",
    "    # Convert image to flat array and JSON format\n",
    "    image_flat = image_to_flat_array(image_processed)\n",
    "    image_json = image_to_json(image_flat)\n",
    "\n",
    "    # Send request to OpenVINO server\n",
    "    url = 'https://testing-mlops.apps.cluster-5djnl.dynamic.redhatworkshops.io/v2/models/testing/infer'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    try:\n",
    "        response = requests.post(url, data=image_json, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            # Parse response\n",
    "            results = json.loads(response.text)\n",
    "\n",
    "            # Get class labels\n",
    "            class_labels = load_class_labels()\n",
    "\n",
    "            # Get the top-1 prediction\n",
    "            predictions = np.array(response.json()['outputs'][0]['data'])\n",
    "            top_prediction_idx = np.argmax(predictions)\n",
    "            top_prediction_label = class_labels[top_prediction_idx]\n",
    "\n",
    "            return top_prediction_label\n",
    "    except Exception as e:\n",
    "        return \"Error: {}\".format(e)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        # Check if the post request has the file part\n",
    "        if 'file' not in request.files:\n",
    "            return render_template('index.html', message='No file part')\n",
    "        file = request.files['file']\n",
    "        # If user does not select file, browser also\n",
    "        # submit an empty part without filename\n",
    "        if file.filename == '':\n",
    "            return render_template('index.html', message='No selected file')\n",
    "        if file:\n",
    "            # Perform inference\n",
    "            result = perform_inference(file)\n",
    "            return render_template('result.html', prediction=result)\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  app.run(debug=False, host=\"0.0.0.0\", port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4465f6a-6be2-4fb6-ab94-0b7d92c61ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
